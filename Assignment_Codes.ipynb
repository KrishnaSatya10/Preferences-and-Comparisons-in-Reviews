{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9H8D2QDhxAD"
   },
   "source": [
    "##### Author: Krishna Prasanna Bhamidipati (kbhamid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d1dAM-ubhxAK"
   },
   "outputs": [],
   "source": [
    "#Load the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,string\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras \n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFltRqll70m0",
    "outputId": "0d789ce9-e9aa-4e4b-d42c-fe72e2a482af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.10.2)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.0.17)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu102)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu102)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DRQnexrhxAM"
   },
   "source": [
    "### LOADING AND UNDERSTANDING DATASET\n",
    "In the below two cells, training and test datasets have been loaded. No additional data has been used for this project (apart from the word-embedding text files which are loaded along with word-embedding pre-trained models). \n",
    "Basic commands have been run to understand the size of the data, the columns and data-types there are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmSW0Rsy64bd",
    "outputId": "d02b68db-59bb-4f92-cf19-a1ed20ae0498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/My Drive/Colab Notebooks/CSC791 NATURAL LANGUAGE PROCESSING\n"
     ]
    }
   ],
   "source": [
    "# Path to the NGSIM data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "%cd /content/drive/My Drive/Colab Notebooks/CSC791 NATURAL LANGUAGE PROCESSING/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TmIZGkQThxAM"
   },
   "outputs": [],
   "source": [
    "#Import the datasets\n",
    "train_data = pd.read_excel('P1_labeled_dataset.xlsx')\n",
    "test_data = pd.read_excel('P1_test_dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "J9dkyCrzhxAN",
    "outputId": "64aaa815-9110-4556-9dda-45a8745ddbdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape  (4829, 6)\n",
      "Test data shape  (1000, 6) \n",
      "\n",
      "Train data columns and datatypes: \n",
      "sentId             int64\n",
      "sentence          object\n",
      "comparison         int64\n",
      "preferred         object\n",
      "mentioned_apps    object\n",
      "current_app       object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentId</th>\n",
       "      <th>sentence</th>\n",
       "      <th>comparison</th>\n",
       "      <th>preferred</th>\n",
       "      <th>mentioned_apps</th>\n",
       "      <th>current_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Might need to switch to Spotify...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>['Spotify']</td>\n",
       "      <td>Pandora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Instagram is a copy cat btw.</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>['instagram']</td>\n",
       "      <td>Snapchat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Way better than pandora.</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>['Pandora']</td>\n",
       "      <td>Spotify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>one of two (chase) banking apps i’ve never had...</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>['Chase Mobile®']</td>\n",
       "      <td>Citi Mobile®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It's awesome, I got it recommended by a friend...</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>['Temple Run 2']</td>\n",
       "      <td>Subway Surfers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Way better compared to sound cloud and pandora...</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>['Pandora']</td>\n",
       "      <td>Spotify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>No problems with crashing, and more expansive ...</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>['NYTimes – Breaking Politics, National &amp; Worl...</td>\n",
       "      <td>The Washington Post Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>it's better than pandora</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>['Pandora']</td>\n",
       "      <td>Spotify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Compare Bank of America mobile app</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>['Bank of America - Mobile Banking']</td>\n",
       "      <td>Wells Fargo Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>the update, occurring on December 17, 2018, wi...</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>['instagram']</td>\n",
       "      <td>Tumblr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentId  ...                  current_app\n",
       "0       0  ...                      Pandora\n",
       "1       1  ...                     Snapchat\n",
       "2       2  ...                      Spotify\n",
       "3       3  ...                 Citi Mobile®\n",
       "4       4  ...               Subway Surfers\n",
       "5       5  ...                      Spotify\n",
       "6       6  ...  The Washington Post Classic\n",
       "7       7  ...                      Spotify\n",
       "8       8  ...           Wells Fargo Mobile\n",
       "9       9  ...                       Tumblr\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running basic sanity checks:\n",
    "print(\"Train data shape \", train_data.shape)\n",
    "print(\"Test data shape \", test_data.shape, '\\n')\n",
    "\n",
    "print(\"Train data columns and datatypes: \")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EELM-BQ5hxAO"
   },
   "source": [
    "### PREPROCESSING --- SENTENCE CLEANING AND TRANSFORMATION\n",
    "In the three cells below we perform following steps:\n",
    "1. A new column called cleaned_sentence is created which is devoid of punctuation. It contains only lower-case words without any leading/trailing whitespaces. \n",
    "2. Cleaned sentences are tokenized\n",
    "\n",
    "    <font color = 'Orange'> Note: I have tried nltk's word_tokenize method,but it does not have a built-in capability to remove punctuations. Hence I first substituted for all punctuations with a '' character using regex sub method. Then perform simple string split function to split the sentence into tokens. </font> \n",
    "\n",
    "3. The preferred column consits of categorical labels which the model will not allow. They are mapped to numerical labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7ExRq-ThxAP"
   },
   "source": [
    "##### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "cvrdMC21hxAQ",
    "outputId": "6908a692-1b7c-4d77-aa2c-047da1fb3cb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentId</th>\n",
       "      <th>sentence</th>\n",
       "      <th>comparison</th>\n",
       "      <th>preferred</th>\n",
       "      <th>mentioned_apps</th>\n",
       "      <th>current_app</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "      <th>tokenized_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Might need to switch to Spotify...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['Spotify']</td>\n",
       "      <td>Pandora</td>\n",
       "      <td>might need to switch to spotify</td>\n",
       "      <td>[might, need, to, switch, to, spotify]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Instagram is a copy cat btw.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['instagram']</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>instagram is a copy cat btw</td>\n",
       "      <td>[instagram, is, a, copy, cat, btw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Way better than pandora.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['Pandora']</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>way better than pandora</td>\n",
       "      <td>[way, better, than, pandora]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>one of two (chase) banking apps i’ve never had...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Chase Mobile®']</td>\n",
       "      <td>Citi Mobile®</td>\n",
       "      <td>one of two chase banking apps ive never had an...</td>\n",
       "      <td>[one, of, two, chase, banking, apps, ive, neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It's awesome, I got it recommended by a friend...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['Temple Run 2']</td>\n",
       "      <td>Subway Surfers</td>\n",
       "      <td>its awesome i got it recommended by a friend a...</td>\n",
       "      <td>[its, awesome, i, got, it, recommended, by, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentId  ...                                     tokenized_sent\n",
       "0       0  ...             [might, need, to, switch, to, spotify]\n",
       "1       1  ...                 [instagram, is, a, copy, cat, btw]\n",
       "2       2  ...                       [way, better, than, pandora]\n",
       "3       3  ...  [one, of, two, chase, banking, apps, ive, neve...\n",
       "4       4  ...  [its, awesome, i, got, it, recommended, by, a,...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize labeled data:-- Take each row and generate corresponding tokens \n",
    "#Make words in the sentence lower case and also remove white spaces. \n",
    "#CreateD an additional column called as 'clean sentence' - the word embedding techniques are implemented on this. \n",
    "train_data['cleaned_sentence'] = train_data['sentence'].apply(lambda r: re.sub(r'[^\\w\\s]', '', str(r).lower().strip()))\n",
    "train_data['tokenized_sent']  = train_data['cleaned_sentence'].apply(lambda r: r.split())                                      \n",
    "\n",
    "mapping_dict = {'T':1,'O':2,'N':3}\n",
    "train_data['preferred'] = train_data['preferred'].map(mapping_dict)\n",
    "\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggO79V5zhxAR"
   },
   "source": [
    "##### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S9ukFH60hxAS"
   },
   "outputs": [],
   "source": [
    "#Tokenize labeled data:-- Take each row and generate corresponding tokens \n",
    "#Make words in the sentence lower case and also remove white spaces. \n",
    "#CreateD an additional column called as 'clean sentence' - the word embedding techniques are implemented on this. \n",
    "test_data['cleaned_sentence'] = test_data['sentence'].apply(lambda r: re.sub(r'[^\\w\\s]', '', str(r).lower().strip()))\n",
    "test_data['tokenized_sent']  = test_data['cleaned_sentence'].apply(lambda r: r.split())                                      \n",
    "\n",
    "mapping_dict = {'T':1,'O':2,'N':3}\n",
    "reverse_mapping_dict = {1:'T',2:'O',3:'N'}\n",
    "test_data['preferred'] = test_data['preferred'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qgj7ir7ChxAS",
    "outputId": "7a904346-0082-4c03-ea42-eaaab01f23de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "BASELINE MODEL STARTS HERE\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 100)\n",
    "print(\"BASELINE MODEL STARTS HERE\")\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTg3M3f1hxAT"
   },
   "source": [
    "# <FONT COLOR = \"RED\"> BASELINE MODEL </FONT>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXhBUPighxAU"
   },
   "source": [
    "### GENERATING WORD AND SENTENCE EMBEDDINGS\n",
    "\n",
    "1. The embedding models used here in building the base-line models are spaCY and TF-IDF vectorization techniques. \n",
    "2. These embedding models are different from one another -- while spaCy is a pre-trained model with one of the fastest execution speeds, TF-IDF word embeddings are generated by exploiting the text-corpus we have provided to it (it is not a pre-trained model). \n",
    "3. Other embedding techniques like word2vec, glove were also tested in baseline model but they performed poorly for selected choice of evaluation metrics. \n",
    "\n",
    "<font color = \"Orange\"> Note: FOR OUR BASELINE MODEL, WE USE ONLY THE `CLEANED_SENTENCE` AND `TOKENIZED_SENT` COLUMNS. *** I.E. LEMMATIZED TOKENS AND THOSE TREATED FOR STOP-WORDS HAVE NOT BEEN USED FOR THIS TASK. ***\n",
    "    HOWEVER, THE WORDS ARE ALL LOWER-CASE AND PUNCTUATION HAS BEEN REMOVED WHERE UNNECESSARY. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uHzJ2W5lhxAU"
   },
   "outputs": [],
   "source": [
    "# LOADING AND INITIALIZING WORD-EMBEDDING MODELS.\n",
    "# Load the spacy model\n",
    "# The spacy model is applied directly on the sentence itself.\n",
    "# It automatically computes the mean of individual words' embeddings in a sentence to get the corresponding sentence embedding.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "## Tf-Idf vectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvOjH863hxAV"
   },
   "source": [
    "#### NOTE ON SPACY AND TFIDF EMBEDDINGS\n",
    "\n",
    "\n",
    "spaCy embeddings model applies on the entire sentence. i.e. it generates word-embeddings for individual words in a sentence *IMPLICITLY*, and it automatically generates the sentence embedding by taking an average of all its word-embeddings. \n",
    "Similarly, TF-IDF words on the whole text-corpus, and hence it computes the sentence embedding directly. (Each element in a single sentence embeddind corresponds to TF-IDF of the word that the element corresponds to. *IN OTHER WORDS, THE WORD-EMBEDDING SIZE IN TF-IDF IS A SCALAR FLOAT VALUE.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjSvSnR-hxAV"
   },
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LxCgLphDhxAV"
   },
   "outputs": [],
   "source": [
    "#Generate sentence embeddings\n",
    "train_data['spacy_embeddings'] = train_data['cleaned_sentence'].apply(lambda s: nlp(s).vector)\n",
    "\n",
    "text_corpus = train_data[\"cleaned_sentence\"]\n",
    "tfidf_train_matrix = tfidf.fit_transform(text_corpus)\n",
    "tfidf_train_vocabulary = tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YM38Xp6vhxAW"
   },
   "source": [
    "##### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DjtNmJKrhxAW"
   },
   "outputs": [],
   "source": [
    "test_data['spacy_embeddings'] = test_data['cleaned_sentence'].apply(lambda s: nlp(s).vector)\n",
    "tfidf_test_matrix = tfidf.transform(test_data[\"cleaned_sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_fwSYlxhxAW"
   },
   "source": [
    "### DATASET PREPARATION FOR MODEL\n",
    "1. This step involves creating a train dataset which consists of only the sentence embeddings generated from above steps. \n",
    "2. Two label series are generated - One for preference classification and other for comparison classification. These two are fed as y-labels to our baseline classification algorithms in-turn and accuracy is computed for each. \n",
    "\n",
    "<font color = \"Orange\"> Note: NO TRAIN AND TEST SPLIT HAS BEEN PERFORMED BASED ON MOODLE DISCUSSION. THE ENTIRE DATA HAS BEEN USED FOR TRAINING </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1MecTUYhxAW"
   },
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N7n28WyhhxAW"
   },
   "outputs": [],
   "source": [
    "#Creating individual training datasets\n",
    "train_spacy_sentences = np.asarray(train_data['spacy_embeddings'].tolist())\n",
    "train_tfidf_sentences = tfidf_train_matrix.copy()\n",
    "train_pref_labels = np.asarray(train_data['preferred'].tolist())\n",
    "train_comp_labels = np.asarray(train_data['comparison'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaJG4FqohxAX"
   },
   "source": [
    "##### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ritN8HpuhxAX"
   },
   "outputs": [],
   "source": [
    "#Creating individual training datasets\n",
    "test_spacy_sentences = np.asarray(test_data['spacy_embeddings'].tolist())\n",
    "test_tfidf_sentences = tfidf_test_matrix.copy()\n",
    "test_pref_labels = np.asarray(test_data['preferred'].tolist())\n",
    "test_comp_labels = np.asarray(test_data['comparison'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I42BlmshxAX"
   },
   "source": [
    "### MODEL SELECTION\n",
    "The models selected for these tasks are Random Forest classifier and multi-nomial Logistic Regression classifier. These models have been selected because they support multi-class classification which is desired for our tasks.\n",
    "\n",
    "### EVALUATION METRICS\n",
    "1. Accuracy score - Since we have multi-class classification, accuracy is a good evaluation metric to gauge how our models are performing. \n",
    "2. Confusion matrix - Confusion matrix is being printed out to understand our classification model better and access which classes are being most misclassified. \n",
    "\n",
    "### MODEL BUILDING\n",
    "There will be 8 models run in total -- 4 models for each label such that - 2 embeddings are covered, two classification algorithms are covered. For each task, following steps have been implemented:\n",
    "1. `random_forest_classification` and `multi_logistic_regression_classificatin` functions train on training data and predict for test data. Each of these functions are called 4 times, for two different set of labels, for two different embedding techniques\n",
    "2. For both tasks accuracy scores from models are computed,confusion matrices are printed out and other evaluation metrics are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhmbzqhQhxAX"
   },
   "source": [
    "#### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Yr6gvInzhxAX"
   },
   "outputs": [],
   "source": [
    "# Fit Random Forest Classification to the training set, predict the class labels for test data.\n",
    "def random_forest_classification(X_train,y_train,X_test,y_test,task, embedding):\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    if (task == 'Preferences'):\n",
    "        y_test = np.vectorize(reverse_mapping_dict.get)(y_test)\n",
    "        y_pred = np.vectorize(reverse_mapping_dict.get)(y_pred)\n",
    "   \n",
    "    # Create Confusion Matrix\n",
    "    print(f'Random Forest Confusion Matrix for {task} label classification for {embedding} embedding:')\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "    \n",
    "    #Print accuracy scores\n",
    "    print('\\n')\n",
    "    rf_acc_score=accuracy_score(y_test,y_pred)\n",
    "    print(f'Random Forest Accuracy for {task} label classification for {embedding} embedding: {rf_acc_score}')\n",
    "\n",
    "    #Print other evaluation scores\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "          \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOYV_ul1hxAX"
   },
   "source": [
    "#### Multinomial Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YVEs2os4hxAY"
   },
   "outputs": [],
   "source": [
    "# Fit Multinomial Logistic Regression Classification to the training set, predict the class labels for test data.\n",
    "def multi_logistic_regression_classification(X_train,y_train,X_test,y_test,task,embedding):\n",
    "    classifier = LogisticRegression (multi_class=\"multinomial\",solver='newton-cg')\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_probs = classifier.predict_proba(X_test)\n",
    "    if (task == 'Preferences'):\n",
    "        y_test = np.vectorize(reverse_mapping_dict.get)(y_test)\n",
    "        y_pred = np.vectorize(reverse_mapping_dict.get)(y_pred)\n",
    "    \n",
    "    # Create Confusion Matrix\n",
    "    print(f'Logistic Regression Confusion Matrix for {task} label classification for {embedding} embedding:')\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "    \n",
    "    #Print accuracy scores\n",
    "    nb_acc_score=accuracy_score(y_test,y_pred)\n",
    "    print(f'Logistic Regression for {task} label classification for {embedding} embedding: {nb_acc_score}')\n",
    "    \n",
    "    #Print other evaluation scores\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5RxkhNmhxAY"
   },
   "source": [
    "### MODEL IMPLEMENTATION\n",
    "There are four calls to each classification algorithm - since there are 2 embedding types and 2 labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Raa81IFNhxAY"
   },
   "source": [
    "##### Random Forest Classification - Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTEy6AlghxAY",
    "outputId": "8a66dc97-c969-4c01-82bb-dd0b89956c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix for Preferences label classification for Spacy embedding:\n",
      "Predicted    N    O    T\n",
      "Actual                  \n",
      "N          150   73   67\n",
      "O           53  214   76\n",
      "T           33   49  285\n",
      "\n",
      "\n",
      "Random Forest Accuracy for Preferences label classification for Spacy embedding: 0.649\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.64      0.52      0.57       290\n",
      "           O       0.64      0.62      0.63       343\n",
      "           T       0.67      0.78      0.72       367\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.65      0.64      0.64      1000\n",
      "weighted avg       0.65      0.65      0.64      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spacy embedding - preference labels\n",
    "random_forest_classification(train_spacy_sentences,train_pref_labels,test_spacy_sentences,test_pref_labels,'Preferences','Spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7tSvW54hxAY",
    "outputId": "64883c30-bc0a-427f-9c9b-7813fad4426e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix for Comparison label classification for Spacy embedding:\n",
      "Predicted   0    1    2\n",
      "Actual                 \n",
      "0          65   46   37\n",
      "1          18  360   83\n",
      "2          13  113  265\n",
      "\n",
      "\n",
      "Random Forest Accuracy for Comparison label classification for Spacy embedding: 0.69\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.44      0.53       148\n",
      "           1       0.69      0.78      0.73       461\n",
      "           2       0.69      0.68      0.68       391\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.63      0.65      1000\n",
      "weighted avg       0.69      0.69      0.68      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spacy embedding - comparison labels\n",
    "random_forest_classification(train_spacy_sentences,train_comp_labels,test_spacy_sentences,test_comp_labels,'Comparison','Spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYuV6pChhxAY",
    "outputId": "59e789a6-153d-4189-e825-235f6321eef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix for Preferences label classification for TF-IDF embedding:\n",
      "Predicted    N    O    T\n",
      "Actual                  \n",
      "N          177   61   52\n",
      "O           50  248   45\n",
      "T           37   39  291\n",
      "\n",
      "\n",
      "Random Forest Accuracy for Preferences label classification for TF-IDF embedding: 0.716\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.67      0.61      0.64       290\n",
      "           O       0.71      0.72      0.72       343\n",
      "           T       0.75      0.79      0.77       367\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.71      0.71      0.71      1000\n",
      "weighted avg       0.71      0.72      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF embedding - preference labels\n",
    "random_forest_classification(train_tfidf_sentences,train_pref_labels,test_tfidf_sentences,test_pref_labels,'Preferences','TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67NA8XduhxAZ",
    "outputId": "f7279936-1d32-460a-c10d-5a22fdd346a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix for Comparison label classification for TF-IDF embedding:\n",
      "Predicted   0    1    2\n",
      "Actual                 \n",
      "0          69   54   25\n",
      "1          11  418   32\n",
      "2           3   94  294\n",
      "\n",
      "\n",
      "Random Forest Accuracy for Comparison label classification for TF-IDF embedding: 0.781\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.47      0.60       148\n",
      "           1       0.74      0.91      0.81       461\n",
      "           2       0.84      0.75      0.79       391\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.80      0.71      0.73      1000\n",
      "weighted avg       0.79      0.78      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF embedding - comparison labels\n",
    "random_forest_classification(train_tfidf_sentences,train_comp_labels,test_tfidf_sentences,test_comp_labels,'Comparison','TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nPS45mihxAZ"
   },
   "source": [
    "##### Logistic Regression Classification - Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-S-KsWzhxAZ",
    "outputId": "d214c495-70c6-4d21-b20e-4942d93fcb09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix for Preferences label classification for Spacy embedding:\n",
      "Predicted    N    O    T\n",
      "Actual                  \n",
      "N          139   78   73\n",
      "O           70  180   93\n",
      "T           57   62  248\n",
      "Logistic Regression for Preferences label classification for Spacy embedding: 0.567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.52      0.48      0.50       290\n",
      "           O       0.56      0.52      0.54       343\n",
      "           T       0.60      0.68      0.64       367\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.56      0.56      0.56      1000\n",
      "weighted avg       0.56      0.57      0.56      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spacy embedding - preference labels\n",
    "multi_logistic_regression_classification(train_spacy_sentences,train_pref_labels,test_spacy_sentences,test_pref_labels,'Preferences','Spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdmJcCb3hxAZ",
    "outputId": "ad24df82-fb91-4868-e3da-4cec08308e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix for Comparison label classification for Spacy embedding:\n",
      "Predicted   0    1    2\n",
      "Actual                 \n",
      "0          21   59   68\n",
      "1          25  321  115\n",
      "2          12  112  267\n",
      "Logistic Regression for Comparison label classification for Spacy embedding: 0.609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.14      0.20       148\n",
      "           1       0.65      0.70      0.67       461\n",
      "           2       0.59      0.68      0.63       391\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.54      0.51      0.50      1000\n",
      "weighted avg       0.59      0.61      0.59      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spacy embedding - comparison labels\n",
    "multi_logistic_regression_classification(train_spacy_sentences,train_comp_labels,test_spacy_sentences,test_comp_labels,'Comparison','Spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7N9BU_zQhxAa",
    "outputId": "22094045-0068-438c-af02-0aa28cd9cc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix for Preferences label classification for TF-IDF embedding:\n",
      "Predicted    N    O    T\n",
      "Actual                  \n",
      "N          189   69   32\n",
      "O           41  267   35\n",
      "T           31   39  297\n",
      "Logistic Regression for Preferences label classification for TF-IDF embedding: 0.753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.72      0.65      0.69       290\n",
      "           O       0.71      0.78      0.74       343\n",
      "           T       0.82      0.81      0.81       367\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.75      0.75      0.75      1000\n",
      "weighted avg       0.75      0.75      0.75      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF embedding - preference labels\n",
    "multi_logistic_regression_classification(train_tfidf_sentences,train_pref_labels,test_tfidf_sentences,test_pref_labels,'Preferences','TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sjxKPHnhxAa",
    "outputId": "4e172d36-ba92-407e-bc34-b1760c97f8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix for Comparison label classification for TF-IDF embedding:\n",
      "Predicted   0    1    2\n",
      "Actual                 \n",
      "0          49   47   52\n",
      "1           9  379   73\n",
      "2           5   63  323\n",
      "Logistic Regression for Comparison label classification for TF-IDF embedding: 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.33      0.46       148\n",
      "           1       0.78      0.82      0.80       461\n",
      "           2       0.72      0.83      0.77       391\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.76      0.66      0.68      1000\n",
      "weighted avg       0.75      0.75      0.74      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF embedding - comparison labels\n",
    "multi_logistic_regression_classification(train_tfidf_sentences,train_comp_labels,test_tfidf_sentences,test_comp_labels,'Comparison','TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHse3RUAhxAa",
    "outputId": "5ce54ea9-d2c6-47f0-c4d1-c26c87b0e7c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "BASELINE MODEL ENDS HERE\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 100)\n",
    "print(\"BASELINE MODEL ENDS HERE\")\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjvpF3aVhxAa",
    "outputId": "3aca29e1-6dd2-4b5d-cf81-d38a460ba324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "PROPOSED MODEL STARTS HERE\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 100)\n",
    "print(\"PROPOSED MODEL STARTS HERE\")\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQIOa0tChxAa"
   },
   "source": [
    "# <FONT COLOR = \"RED\">PROPOSED MODEL </FONT>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57Ya7VaLhxAa"
   },
   "source": [
    "### PREPROCESSING - STOP WORDS REMOVAL AND LEMMATIZATION\n",
    "\n",
    "For our baseline model we generated a `cleaned_sentence` column in our dataset. This sentence had no punctuations, whitespaces and capital letters. We perform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LA51O4vchxAa"
   },
   "outputs": [],
   "source": [
    "#Remove leading and trailing white spaces\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(sentence):\n",
    "    return ' '.join([word for word in sentence.split() if word not in stopwords])\n",
    "\n",
    "#Perform lemmatization to get root words. \n",
    "def get_lemmatized_word(sentence):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfOVDPxmhxAb"
   },
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ab-XEoJShxAb"
   },
   "outputs": [],
   "source": [
    "# #Clean the sentence further by removing stopwords and getting lemmatized word\n",
    "train_data['extra_cleaned_sentence'] = train_data['cleaned_sentence'].apply(lambda s: remove_stopwords(s)).apply(lambda s: get_lemmatized_word(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw7S30jRTwfy"
   },
   "source": [
    "##### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "X2aPWUWNhxAb"
   },
   "outputs": [],
   "source": [
    "# #Clean tokens by removing stopwords and getting lemmatized word\n",
    "test_data['extra_cleaned_sentence'] = test_data['cleaned_sentence'].apply(lambda s: remove_stopwords(s)).apply(lambda s: get_lemmatized_word(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo-s39qdhxAb"
   },
   "source": [
    "### WORD EMBEDDINGS -- UNIVERSAL SENTENCE ENCODER\n",
    "In this module Google's universal sentence encoder is used to generate sentence embeddings. Sentence Transformers were used to generate the embeddings as well but the model performance was comparitively better when using this technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GukMk3bthxAb",
    "outputId": "c1b14ebb-f747-4fbc-d0a5-74b8f16cfe02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "#Load the encoder\n",
    "universal_sentence_encoder  = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "\n",
    "#Generate sentence embeddings using universal sentence encoder.\n",
    "train_US_embeddings = universal_sentence_encoder(train_data['cleaned_sentence'].values.tolist())\n",
    "test_US_embeddings = universal_sentence_encoder(test_data['cleaned_sentence'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75KbA8XnJkyl"
   },
   "source": [
    "### MODEL\n",
    "1. XGBoost is a boosting based ensemble decision tree algorithm which as been used to model the data. 200 weak estimators have been used to train the model. Refer to the function xgboost_classification\n",
    "2. The same evaluation metrics used in baseline model have also been used here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "D6WtM7R_hxAb"
   },
   "outputs": [],
   "source": [
    "def xgboost_classification(X_train,y_train,X_test,y_test,task, embedding):\n",
    "  classifier = XGBClassifier(n_estimators=200)\n",
    "  classifier.fit(X_train, y_train)\n",
    "\n",
    "  # Predict the test set results\n",
    "  y_pred = classifier.predict(X_test)\n",
    "  y_pred_probs = classifier.predict_proba(X_test)\n",
    "  if (task == 'Preferences'):\n",
    "      y_test = np.vectorize(reverse_mapping_dict.get)(y_test)\n",
    "      y_pred = np.vectorize(reverse_mapping_dict.get)(y_pred)\n",
    "  \n",
    "  # Create Confusion Matrix\n",
    "  print(f'XGBoost Confusion Matrix for {task} label classification for {embedding} embedding:')\n",
    "  print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "  \n",
    "  #Print accuracy scores\n",
    "  nb_acc_score=accuracy_score(y_test,y_pred)\n",
    "  print(f'XGBoost for {task} label classification for {embedding} embedding: {nb_acc_score}')\n",
    "  \n",
    "  #Print other evaluation scores\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cKRkHIPTaOc"
   },
   "source": [
    "##### XGBoost Classification - Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oC8c8ecFtr5",
    "outputId": "ca33fe8e-c558-4a82-a471-263e48b1bfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Confusion Matrix for Preferred label classification for Universal Sentence Encoder embedding:\n",
      "Predicted    1    2    3\n",
      "Actual                  \n",
      "1          289   47   31\n",
      "2           49  241   53\n",
      "3           47   47  196\n",
      "XGBoost for Preferred label classification for Universal Sentence Encoder embedding: 0.726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.79      0.77       367\n",
      "           2       0.72      0.70      0.71       343\n",
      "           3       0.70      0.68      0.69       290\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.72      0.72      0.72      1000\n",
      "weighted avg       0.73      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_classification(train_US_embeddings.numpy(),train_pref_labels,test_US_embeddings.numpy(),test_pref_labels,'Preferred','Universal Sentence Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYM2qLQRF5nH",
    "outputId": "cd43d2ce-bb84-4f1c-ecdc-ae53f61048cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Confusion Matrix for Comparison label classification for Universal Sentence Encoder embedding:\n",
      "Predicted   0    1    2\n",
      "Actual                 \n",
      "0          77   50   21\n",
      "1          13  403   45\n",
      "2           7   64  320\n",
      "XGBoost for Comparison label classification for Universal Sentence Encoder embedding: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.52      0.63       148\n",
      "           1       0.78      0.87      0.82       461\n",
      "           2       0.83      0.82      0.82       391\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.80      0.74      0.76      1000\n",
      "weighted avg       0.80      0.80      0.80      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost_classification(train_US_embeddings.numpy(),train_comp_labels,test_US_embeddings.numpy(),test_comp_labels,'Comparison','Universal Sentence Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFlFGHobT2Zs",
    "outputId": "acc8fda0-7425-4f4b-8f61-7ffa97536709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "PROPOSED MODEL ENDS HERE\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 100)\n",
    "print(\"PROPOSED MODEL ENDS HERE\")\n",
    "print(\"*\" * 100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_P1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
